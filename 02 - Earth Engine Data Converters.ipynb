{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "name": "index.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Copyright 2023 The Earth Engine Community Authors { display-mode: \"form\" }\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "3Ep_IfWgIDHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https://)# Earth Engine Data Converters\n",
        "Author: jdbcode\n",
        "\n",
        "Data converters are client-side conversion capabilities built into [`getPixels`](https://developers.google.com/earth-engine/apidocs/ee-data-getpixels), [`computePixels`](https://developers.google.com/earth-engine/apidocs/ee-data-computepixels), [`listFeatures`](https://developers.google.com/earth-engine/apidocs/ee-data-listfeatures), and [`computeFeatures`](https://developers.google.com/earth-engine/apidocs/ee-data-computefeatures). By specifying a compatible `fileFormat`, these methods can return data in Python-native formats like structured NumPy arrays for rasters and Pandas DataFrames or GeoPandas GeoDataFrames for vectors. In the case of vectors, the `listFeatures` and `computeFeatures` methods will make several network requests to fetch all the pages of the table before returning the Python object.\n",
        "\n",
        "All of these methods transfer data from Earth Engine servers to a client machine using the [interactive processing environment](https://developers.google.com/earth-engine/guides/processing_environments#interactive_environment), which is optimized for answering small requests quickly. As such, it enforces limits on request size and compute time. You'll need to keep this in mind as you're coding your analysis and decide whether exporting data using the [batch processing environment](https://developers.google.com/earth-engine/guides/processing_environments#batch_environment) would be better. For example, see `ee.data.computePixel` limits in the [reference docs](https://developers.google.com/earth-engine/reference/rest/v1/projects.image/computePixels).\n",
        "\n",
        "Some common use cases for data converters are fetching many small image tiles in parallel (e.g., training ML models or automated serial workflows) and for visualization and data exploration with your favorite Python libraries. This notebook focuses on data exploration and visualization; if you're interested in learning about fetching data in parallel, see the Medium blog post \"[Pixels to the people!](https://medium.com/google-earth/pixels-to-the-people-2d3c14a46da6)\"."
      ],
      "metadata": {
        "id": "zH_duK7No78T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Import libraries and authenticate to Earth Engine and initialize the API."
      ],
      "metadata": {
        "id": "rUSOJ7iBwQQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import altair as alt\n",
        "import ee\n",
        "import eerepr\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid"
      ],
      "metadata": {
        "id": "n3MPcx_CwlbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-F8V3Ku7mHm"
      },
      "outputs": [],
      "source": [
        "# Authenticate and Initialize Earth Engine\n",
        "import ee\n",
        "# Authenticate as your Qwiklabs User\n",
        "ee.Authenticate()\n",
        "# Initialize the library by specifying the GCP project\n",
        "your_project_id = ''\n",
        "ee.Initialize(project=your_project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "\n",
        "In this notebook we'll be looking at watersheds in Washington state (USA) and long-term climate averages."
      ],
      "metadata": {
        "id": "8i4YqQctWcmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define asset paths for [basins](https://developers.google.com/earth-engine/datasets/catalog/WWF_HydroSHEDS_v1_Basins_hybas_6), [state boundaries](https://developers.google.com/earth-engine/datasets/catalog/FAO_GAUL_2015_level1), and [climate averages](https://developers.google.com/earth-engine/datasets/catalog/WORLDCLIM_V1_MONTHLY)."
      ],
      "metadata": {
        "id": "o29zCdggSOCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASINS_ID = 'WWF/HydroSHEDS/v1/Basins/hybas_6'\n",
        "BOUNDARIES_ID = 'FAO/GAUL/2015/level1'\n",
        "CLIMATE_ID = 'WORLDCLIM/V1/MONTHLY'"
      ],
      "metadata": {
        "id": "P8XV8eVDSLLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the basins asset and subset watersheds that intersect Washington state. The result is a `ee.FeatureCollection`."
      ],
      "metadata": {
        "id": "_IbFYce5SZtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basins = ee.FeatureCollection(BASINS_ID)\n",
        "wa = ee.FeatureCollection(BOUNDARIES_ID).filter(\n",
        "    'ADM0_NAME == \"United States of America\" && '\n",
        "    'ADM1_NAME == \"Washington\"'\n",
        ")\n",
        "\n",
        "wa_basins = basins.filterBounds(wa)"
      ],
      "metadata": {
        "id": "gpqewRSgCTMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the WorldClim climate image collection (each image is the average historical climate for a month), subset the precipitation band and stack the individual images into a single image (each band represents a historical monthly mean). Inspect the resulting `ee.Image` band names to see that bands are named like `prec_month_01` and `prec_month_02`, indicating mean precipitation for January and February, respectively."
      ],
      "metadata": {
        "id": "iau9Sav7SgTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precip = ee.ImageCollection(CLIMATE_ID).select('prec')\n",
        "\n",
        "months = precip.aggregate_array('month').getInfo()\n",
        "\n",
        "band_names = [f'prec_month_{str(m).zfill(2)}' for m in months]\n",
        "\n",
        "monthly_precip = ee.Image(precip.toBands().rename(band_names))\n",
        "\n",
        "monthly_precip.bandNames()"
      ],
      "metadata": {
        "id": "SV5DtihmE81A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate historical mean monthly precipitation for each Washington watershed. These zonal statistics are added as attributes to the `wa_basins` feature collection."
      ],
      "metadata": {
        "id": "-wjsFxcPU5Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wa_basins = monthly_precip.reduceRegions(\n",
        "    collection=wa_basins,\n",
        "    reducer=ee.Reducer.mean(),\n",
        "    scale=1e3\n",
        ")"
      ],
      "metadata": {
        "id": "VJlSKrWoJGJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converters\n",
        "\n",
        "In the following sections we'll convert the Earth Engine objects defined above into Python-native formats for visualization and exploring. A distinction is made between **computed** and **stored** Earth Engine data because data converter functions are specific to each type."
      ],
      "metadata": {
        "id": "6kEOrBCkWvPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computed Earth Engine data\n",
        "\n",
        "Computed Earth Engine data are those that are generated on the fly through instantiation of non-asset data, computation, or manipulation; they are not stored on disk for later retrieval. To request conversion of computed data, you can use the `ee.data.computeFeatures` and `ee.data.computePixels` functions for `ee.FeatureCollection` and `ee.Image` objects, respectively."
      ],
      "metadata": {
        "id": "3G7zFYd1Wxvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `FeatureCollection` to Pandas `DataFrame`\n",
        "\n",
        "An `ee.FeatureCollection` is Earth Engine's table data type. Each `ee.Feature` in the collection can be thought of as a row and each of its properties as a column - one column stores the geometry. The EE API has a rich set of methods for working with feature collections, but feature collections are difficult to view as a table and you may prefer to use [Pandas](https://pandas.pydata.org/) for analysis. We can transfer the data client-side as a Pandas `DataFrame`.\n"
      ],
      "metadata": {
        "id": "JP5PYyTE49EU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can print the head of the Washington watersheds feature collection to preview the table, but the JSON structure makes it hard to interpret and conceptualize as a table (even with the help of `eerep` for rich object representation)."
      ],
      "metadata": {
        "id": "gv67sk9-qo3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wa_basins.limit(5)"
      ],
      "metadata": {
        "id": "f-5szE9oJd0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `ee.data.computeFeatures` with the `fileFormat` parameter set to `'PANDAS_DATAFRAME'` to get the data as a Pandas `DataFrame`.\n",
        "\n"
      ],
      "metadata": {
        "id": "elwIdkRSq7bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wa_basins_df = ee.data.computeFeatures({\n",
        "    'expression': wa_basins,\n",
        "    'fileFormat': 'PANDAS_DATAFRAME'\n",
        "})"
      ],
      "metadata": {
        "id": "ht9YrKy6KyDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the object's type and see that it is `pandas.core.frame.DataFrame\n",
        "`. Printing the head of the object shows the nicely formatted table."
      ],
      "metadata": {
        "id": "2xxl6CWzrhWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(type(wa_basins_df))\n",
        "wa_basins_df.head()"
      ],
      "metadata": {
        "id": "mgInawXQrg7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can use Pandas syntax to convert the wide table into a long table so that month is a factor and precipitation is a variable."
      ],
      "metadata": {
        "id": "hoJPYdHqsN52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wa_basins_df = wa_basins_df.melt(\n",
        "    id_vars=[\"HYBAS_ID\"],\n",
        "    value_vars=band_names,\n",
        "    var_name=\"Month\",\n",
        "    value_name=\"Precipitation\",\n",
        ")\n",
        "wa_basins_df"
      ],
      "metadata": {
        "id": "TvsP6iR5MyMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use Pandas' [`groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) method and built-in [matplotlib charting wrappers](https://pandas.pydata.org/docs/user_guide/visualization.html#basic-plotting-plot) for a quick look at mean total annual precipition for each watershed."
      ],
      "metadata": {
        "id": "ZmoUAUwMn_mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wa_basins_df.groupby(['HYBAS_ID'])['Precipitation'].sum().plot.bar()"
      ],
      "metadata": {
        "id": "zFIQ1WV1gOu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are lots of charting libraries for visualizing `DataFrame` objects. Here, we plot the data with [Altair](https://altair-viz.github.io/gallery/index.html#) using a stacked column chart to show the total mean annual precipitation (by monthly contribution) for each watershed intersecting Washington state.  We can see quite a range in total precipitation and that summer months are generally drier than other months."
      ],
      "metadata": {
        "id": "nAvHPlG_s3oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alt.Chart(wa_basins_df).mark_bar().encode(\n",
        "    x=alt.X('HYBAS_ID:O'),\n",
        "    y=alt.Y('Precipitation:Q', title='Precipitation (mm)'),\n",
        "    color=alt.Color('Month', scale=alt.Scale(scheme='rainbow')),\n",
        "    tooltip=alt.Tooltip(['HYBAS_ID', 'Precipitation', 'Month'])\n",
        ").interactive()"
      ],
      "metadata": {
        "id": "AYDwssWoSgMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `FeatureCollection` to GeoPandas `GeoDataFrame`\n",
        "\n",
        "Use the `ee.data.computeFeatures` with the `fileFormat` parameter set to `'GEOPANDAS_GEODATAFRAME'` to get the Washington basins climate data as a [GeoPandas](https://geopandas.org/en/v0.14.0/index.html) `GeoDataFrame`. It allows you to use the table manipulation and querying functions of Pandas, in addition to geospatial operations and visualizations."
      ],
      "metadata": {
        "id": "Wq4Puu53aALt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wa_basins_gdf = ee.data.computeFeatures({\n",
        "    'expression': wa_basins,\n",
        "    'fileFormat': 'GEOPANDAS_GEODATAFRAME'\n",
        "})\n",
        "\n",
        "# Need to set the CRS.\n",
        "# Make sure it matches the CRS of FeatureCollection geometries.\n",
        "wa_basins_gdf.crs = 'EPSG:4326'\n",
        "\n",
        "display(type(wa_basins_gdf))\n",
        "wa_basins_gdf.head()"
      ],
      "metadata": {
        "id": "6gkcmEYRCkXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch the Washington state boundary as `GeoDataFrame` too."
      ],
      "metadata": {
        "id": "kRb6E8Kqn5Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wa_gdf = ee.data.computeFeatures({\n",
        "    'expression': wa,\n",
        "    'fileFormat': 'GEOPANDAS_GEODATAFRAME'\n",
        "})\n",
        "\n",
        "wa_gdf.crs = 'EPSG:4326'"
      ],
      "metadata": {
        "id": "VRsjLDgLlccc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clip the watershed geometries by the Washington state boundary using the `GeoDataFrame.clip` method and convert the original mercator projection to a Washington-specific projection for better visualization."
      ],
      "metadata": {
        "id": "PUG3kUwvoJRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wa_basins_gdf = wa_basins_gdf.clip(wa_gdf).to_crs(2856)"
      ],
      "metadata": {
        "id": "UVxnlYs40Tsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sum the 12 months of mean precipitation for each watershed and append the values in a new column called `prec_total`."
      ],
      "metadata": {
        "id": "3OGJefNPoz0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wa_basins_gdf['prec_total'] = wa_basins_gdf[band_names].sum(axis=1)\n",
        "wa_basins_gdf.head()"
      ],
      "metadata": {
        "id": "pqMHjXI6yrca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use [matplotlib](https://matplotlib.org/) to plot a choropleth map of mean annual precipitation by watershed and highlight the watershed with the minimum precipitation using a red border."
      ],
      "metadata": {
        "id": "B8spnY3Mpe_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the choropleth map.\n",
        "ax = wa_basins_gdf.plot(\n",
        "    column='prec_total',\n",
        "    cmap='viridis_r',\n",
        "    vmin=wa_basins_gdf['prec_total'].min(),\n",
        "    vmax=wa_basins_gdf['prec_total'].max(),\n",
        "    legend=False,\n",
        "    edgecolor='grey', linewidth=0.5\n",
        ")\n",
        "\n",
        "# Highlight the basin with the minimum annual precipitation: subset the geometry\n",
        "# with the minimum precipitation total and then add it to the basin\n",
        "# precipitation plot.\n",
        "min_prec_gdf = wa_basins_gdf.loc[[wa_basins_gdf['prec_total'].idxmin()]]\n",
        "min_prec_gdf.plot(ax=ax, color='none', edgecolor='red', linewidth=2)\n",
        "\n",
        "# Add axis labels, a colorbar, and rotate x axis ticks.\n",
        "ax.set_xlabel('Eastings [m]')\n",
        "ax.set_ylabel('Northings [m]')\n",
        "colorbar = plt.colorbar(ax.get_children()[0], fraction=0.03)\n",
        "colorbar.set_label('Precipitation (mm)')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A_9g3plzEmci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `Image` to NumPy structured array\n",
        "\n",
        "Here we use `ee.data.computePixels` to request the `monthly_precip` computed Earth Engine image (each band is mean precipitation for a given month) as a [NumPy structured array](https://numpy.org/doc/stable/user/basics.rec.html). It is a global dataset, so we'll request only the Washington state basins bounding region at a resolution of 1500 meters. We can use the [`ee.Image.clipToBoundsAndScale`](https://developers.google.com/earth-engine/apidocs/ee-image-cliptoboundsandscale#colab-python) function to do this, which is a convenient alternative to supplying the `grid` argument."
      ],
      "metadata": {
        "id": "6fYvJO6o2vd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_precip_washington = monthly_precip.clipToBoundsAndScale(\n",
        "    geometry=wa_basins, scale=1500\n",
        ")\n",
        "\n",
        "monthly_precip_npy = ee.data.computePixels({\n",
        "    'expression': monthly_precip_washington,\n",
        "    'fileFormat': 'NUMPY_NDARRAY'\n",
        "})\n",
        "\n",
        "monthly_precip_npy"
      ],
      "metadata": {
        "id": "Zs3DLlxF1V-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy structured arrays work well for multiband image data. You can think of them as a table of arrays where each band is a column accessible from a field (band) name. It also permits each band to have a different data type.\n",
        "\n",
        "For example, get the list of field (band) names and then subset an array by name and print its shape and display a preview of it."
      ],
      "metadata": {
        "id": "Q-O7ZjcZ5EHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = monthly_precip_npy.dtype.names\n",
        "print('field names:', names)\n",
        "\n",
        "prec_month_10_arr = monthly_precip_npy['prec_month_10']\n",
        "print('Selected array (band) shape:', prec_month_10_arr.shape)\n",
        "display(prec_month_10_arr)\n",
        "plt.imshow(prec_month_10_arr, vmin=0, vmax=320)"
      ],
      "metadata": {
        "id": "gyPBhfG-Jh2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have all months of mean precipitation, we can use the matplotlib [`ImageGrid`](https://matplotlib.org/stable/gallery/axes_grid1/simple_axesgrid.html) function to show a time series grid for simple visual interpolation of intra-annual precipitation patterns."
      ],
      "metadata": {
        "id": "Zr-idF22ALDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the figure and grid.\n",
        "fig = plt.figure(figsize=(20.0, 20.0))\n",
        "grid = ImageGrid(\n",
        "    fig,\n",
        "    111,\n",
        "    nrows_ncols=(4, 3),\n",
        "    axes_pad=0.4,\n",
        "    cbar_mode=\"single\",\n",
        "    cbar_location=\"right\",\n",
        "    cbar_pad=0.4,\n",
        "    cbar_size=\"2%\",\n",
        ")\n",
        "\n",
        "# Display each band to a grid cell.\n",
        "for ax, name in zip(grid, names):\n",
        "    ax.imshow(monthly_precip_npy[name], vmin=0, vmax=500)\n",
        "    ax.set_title(name)\n",
        "\n",
        "# Add colorbar.\n",
        "colorbar = plt.colorbar(ax.get_children()[0], cax=grid[0].cax)\n",
        "colorbar.set_label(\"Precipitation (mm)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IY_TDTJhq7vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stored Earth Engine data\n",
        "\n",
        "Stored Earth Engine data are those that exist as assets in the [public data catalog](https://developers.google.com/earth-engine/datasets) or personal and shared cloud projects. To request conversion of stored data, you can use the `ee.data.listFeatures` and `ee.data.getPixels` functions for `ee.FeatureCollection` and `ee.Image` objects, respectively."
      ],
      "metadata": {
        "id": "D-LZz_lmXmAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `FeatureCollection` to Pandas `DataFrame`\n",
        "\n",
        "We use the `ee.data.listFeatures` function to get a Pandas `DataFrame` from a stored `FeatureCollection` asset. The process is similar to converting a computed `FeatureCollection` (see above), but since we can't manipulate the `FeatureCollection` there are extra parameters to optionally specify the region and filter by property values. In this case, we subset the global watershed dataset to those that intersect Washington state using the `region` parameter and apply a filter to only include watersheds that are greater than or equal to river order 3, using the `filter` parameter.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HYfswBsWKIEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "high_order_wa_basins_df = ee.data.listFeatures({\n",
        "    'assetId': 'WWF/HydroSHEDS/v1/Basins/hybas_6',\n",
        "    'region': wa.geometry().getInfo(),\n",
        "    'filter': 'ORDER >= 3',\n",
        "    'fileFormat': 'PANDAS_DATAFRAME'\n",
        "})\n",
        "\n",
        "high_order_wa_basins_df"
      ],
      "metadata": {
        "id": "pWSjUpch8vI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `FeatureCollection` to GeoPandas `GeoDataFrame`\n",
        "\n",
        "If we change the `fileFormat` argument to `'GEOPANDAS_GEODATAFRAME'`, we'll get a GeoPandas `GeoDataFrame`."
      ],
      "metadata": {
        "id": "LVVLMDa9Y0cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "high_order_wa_basins_gdf = ee.data.listFeatures({\n",
        "    'assetId': 'WWF/HydroSHEDS/v1/Basins/hybas_6',\n",
        "    'region': wa.geometry().getInfo(),\n",
        "    'filter': 'ORDER >= 3',\n",
        "    'fileFormat': 'GEOPANDAS_GEODATAFRAME'\n",
        "})\n",
        "\n",
        "display(type(wa_basins_gdf))\n",
        "high_order_wa_basins_gdf"
      ],
      "metadata": {
        "id": "bLLDepMLJEeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the high order watersheds in Washington with its border so we can see their location in the state."
      ],
      "metadata": {
        "id": "Of0rOgE-ePRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an initial plot with the high river order watersheds.\n",
        "ax = high_order_wa_basins_gdf.plot(edgecolor='purple', linewidth=1)\n",
        "\n",
        "# Overlay the Washington state border for context.\n",
        "wa_gdf.plot(ax=ax, color='none', edgecolor='black', linewidth=1)\n",
        "\n",
        "# Set axis labels.\n",
        "ax.set_xlabel('Eastings [degrees]')\n",
        "ax.set_ylabel('Northings [degrees]')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9eptP48n9zsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `Image` to NumPy structured array\n",
        "\n",
        "Here we use `ee.data.getPixels` to request the global historical average temperature for January (according to the WorldClim data) as a NumPy structured array. Unlike `ee.data.computePixels` (above), we can't use the very convenient `ee.Image.clipToBoundsAndScale` function to define the request region and scale because we need to access the asset directly without manipulation. Instead, we have to use the more verbose and less intuitive `grid` parameter.\n",
        "\n",
        "The `grid` argument in our request starts by defining a global 1-degree grid and then applies a scale factor of 5 to get higher resolution."
      ],
      "metadata": {
        "id": "myLrgjnpbXu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SCALE_FACTOR = 5\n",
        "\n",
        "jan_mean_temp_npy = ee.data.getPixels({\n",
        "    'assetId': 'WORLDCLIM/V1/MONTHLY/01',\n",
        "    'fileFormat': 'NUMPY_NDARRAY',\n",
        "    'grid': {\n",
        "        'dimensions': {\n",
        "            'width': 360 * SCALE_FACTOR,\n",
        "            'height': 180 * SCALE_FACTOR\n",
        "        },\n",
        "        'affineTransform': {\n",
        "            'scaleX': 1 / SCALE_FACTOR,\n",
        "            'shearX': 0,\n",
        "            'translateX': -180,\n",
        "            'shearY': 0,\n",
        "            'scaleY': -1 / SCALE_FACTOR,\n",
        "            'translateY': 90\n",
        "        },\n",
        "        'crsCode': 'EPSG:4326',\n",
        "    },\n",
        "    'bandIds': ['tavg']\n",
        "})\n",
        "\n",
        "jan_mean_temp_npy"
      ],
      "metadata": {
        "id": "34t5UOBoffkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the `'tavg'` band from the structured array, set the background values as `nan`, and scale the temperature values to the appropriate range."
      ],
      "metadata": {
        "id": "pyzhqeN4ozUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jan_mean_temp_npy = jan_mean_temp_npy['tavg']\n",
        "\n",
        "jan_mean_temp_npy = np.where(jan_mean_temp_npy < -9999, np.nan, jan_mean_temp_npy)\n",
        "jan_mean_temp_npy = jan_mean_temp_npy * 0.1\n",
        "jan_mean_temp_npy"
      ],
      "metadata": {
        "id": "v3VvyfoZNEON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the 2D array as an image using matplotlib."
      ],
      "metadata": {
        "id": "qemGeuahp1zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10., 10.))\n",
        "ax = plt.imshow(jan_mean_temp_npy, cmap='coolwarm', vmin=-40, vmax=40)\n",
        "\n",
        "colorbar = plt.colorbar(ax, fraction=0.0235)\n",
        "colorbar.set_label('Mean January Temp (°C)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wAyb5bpiMMR4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}